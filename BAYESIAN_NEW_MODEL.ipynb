{
<<<<<<< HEAD
<<<<<<< HEAD
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "from math import sqrt\n",
    "from datetime import datetime,timedelta\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.layers import BatchNormalization, Embedding, TimeDistributed, LeakyReLU\n",
    "from tensorflow.keras.layers import LSTM, GRU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from matplotlib import pyplot\n",
    "from pickle import load\n",
    "from numpy import *\n",
    "from pandas import *\n",
    "from kerastuner import HyperModel\n",
    "from kerastuner.tuners import BayesianOptimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Train-Test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(\"X_train.npy\", allow_pickle=True)\n",
    "Y_train = np.load(\"y_train.npy\", allow_pickle=True)\n",
    "X_test = np.load(\"X_test.npy\", allow_pickle=True)\n",
    "Y_test = np.load(\"y_test.npy\", allow_pickle=True)\n",
    "Yc_train = np.load(\"yc_train.npy\", allow_pickle=True)\n",
    "Yc_test = np.load(\"yc_test.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMHyperModel(HyperModel):\n",
    "    \n",
    "    def __init__(self, input_dim,feature_size,output_dim):\n",
    "        self.input_dim = input_dim\n",
    "        self.feature_size = feature_size\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "    def build(self, hp):\n",
    "        model = Sequential()\n",
    "        model.add(\n",
    "            Bidirectional(LSTM(\n",
    "                units=hp.Int('units_directional', min_value = 32,max_value =512,step = 32),\n",
    "                activation='tanh',\n",
    "                input_shape=(input_dim,feature_size)\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        model.add(\n",
    "            Dense(\n",
    "                units=hp.Int('units_dense', min_value = 32,max_value =512,step = 32),\n",
    "                activation=hp.Choice(\n",
    "                    'dense_activation',\n",
    "                    values=['relu', 'tanh', 'sigmoid'],\n",
    "                    default='relu')\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        model.add(Dense(1))\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=tensorflow.keras.optimizers.Adam(hp.Choice('learning_rate',\n",
    "                      values=[1e-2, 1e-3, 1e-4,2e-2, 2e-3, 2e-4,3e-2, 3e-3, 3e-4,4e-2, 4e-3, 4e-4,5e-2, 5e-3, 5e-4])),loss='mse',metrics=['mse']\n",
    "        )\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "feature_size = X_train.shape[2]\n",
    "output_dim = Y_train.shape[1]\n",
    "hypermodel = LSTMHyperModel(input_dim,feature_size,output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executing Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
=======
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "BAYESIAN_NEW_MODEL.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
>>>>>>> 02a2a658d495b21b2ea1262236116c19d5d23722
=======
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "BAYESIAN_NEW_MODEL.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
>>>>>>> 02a2a658d495b21b2ea1262236116c19d5d23722
    {
      "cell_type": "code",
      "metadata": {
        "id": "fokjd_ykwQsH"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow\n",
        "from math import sqrt\n",
        "from datetime import datetime,timedelta\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.layers import BatchNormalization, Embedding, TimeDistributed, LeakyReLU\n",
        "from tensorflow.keras.layers import LSTM, GRU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from matplotlib import pyplot\n",
        "from pickle import load\n",
        "from numpy import *\n",
        "from pandas import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWVhpiuOxZ34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a214dc3-514c-455d-fd23-ea2d2ab7647c"
      },
      "source": [
        "!pip install -q -U keras-tuner\n",
        "from kerastuner import HyperModel\n",
        "from kerastuner.tuners import BayesianOptimization"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |█████▏                          | 10kB 21.9MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 20kB 29.3MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 30kB 34.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 40kB 30.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 51kB 32.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 61kB 32.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 9.7MB/s \n",
            "\u001b[?25h  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
<<<<<<< HEAD
<<<<<<< HEAD
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner_bo = BayesianOptimization(\n",
    "            hypermodel,\n",
    "            objective='val_loss',\n",
    "            max_trials=10,\n",
    "            seed=42,\n",
    "            executions_per_trial=2\n",
    "        )\n",
    "tuner_bo.search(X_train, Y_train, epochs=100, validation_data=(X_test, Y_test), verbose=4)\n",
    "best_model = tuner_bo.get_best_models(num_models=1)[0]\n",
    "best_model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results of Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
=======
=======
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiQOIZ2awQsL"
      },
      "source": [
        "X_train = np.load(\"X_train.npy\", allow_pickle=True)\n",
        "Y_train = np.load(\"y_train.npy\", allow_pickle=True)\n",
        "X_test = np.load(\"X_test.npy\", allow_pickle=True)\n",
        "Y_test = np.load(\"y_test.npy\", allow_pickle=True)\n",
        "Yc_train = np.load(\"yc_train.npy\", allow_pickle=True)\n",
        "Yc_test = np.load(\"yc_test.npy\", allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
>>>>>>> 02a2a658d495b21b2ea1262236116c19d5d23722
    },
    {
      "cell_type": "code",
      "metadata": {
<<<<<<< HEAD
        "id": "yiQOIZ2awQsL"
      },
      "source": [
        "X_train = np.load(\"X_train.npy\", allow_pickle=True)\n",
        "Y_train = np.load(\"y_train.npy\", allow_pickle=True)\n",
        "X_test = np.load(\"X_test.npy\", allow_pickle=True)\n",
        "Y_test = np.load(\"y_test.npy\", allow_pickle=True)\n",
        "Yc_train = np.load(\"yc_train.npy\", allow_pickle=True)\n",
        "Yc_test = np.load(\"yc_test.npy\", allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
>>>>>>> 02a2a658d495b21b2ea1262236116c19d5d23722
    {
      "cell_type": "code",
      "metadata": {
=======
>>>>>>> 02a2a658d495b21b2ea1262236116c19d5d23722
        "id": "m8njPWI1wQsM"
      },
      "source": [
        "class LSTMHyperModel(HyperModel):\n",
        "    \n",
        "    def __init__(self, input_dim,feature_size,output_dim):\n",
        "        self.input_dim = input_dim\n",
        "        self.feature_size = feature_size\n",
        "        self.output_dim = output_dim\n",
        "        \n",
        "    def build(self, hp):\n",
        "        model = Sequential()\n",
        "        model.add(\n",
        "            Bidirectional(LSTM(\n",
        "                units=hp.Int('units_directional', min_value = 32,max_value =512,step = 32),\n",
        "                activation='tanh',\n",
        "                input_shape=(input_dim,feature_size)\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "        \n",
        "        model.add(\n",
        "            Dense(\n",
        "                units=hp.Int('units_dense', min_value = 32,max_value =512,step = 32),\n",
        "                activation=hp.Choice(\n",
        "                    'dense_activation',\n",
        "                    values=['relu', 'tanh', 'sigmoid'],\n",
        "                    default='relu')\n",
        "            )\n",
        "        )\n",
        "        \n",
        "        model.add(Dense(1))\n",
        "        \n",
        "        model.compile(\n",
        "            optimizer=tensorflow.keras.optimizers.Adam(hp.Choice('learning_rate',\n",
        "                      values=[1e-2, 1e-3, 1e-4,2e-2, 2e-3, 2e-4,3e-2, 3e-3, 3e-4,4e-2, 4e-3, 4e-4,5e-2, 5e-3, 5e-4])),loss='mse',metrics=['mse']\n",
        "        )\n",
        "        \n",
        "        return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TmVrsjJwQsN"
      },
      "source": [
        "input_dim = X_train.shape[1]\n",
        "feature_size = X_train.shape[2]\n",
        "output_dim = Y_train.shape[1]\n",
        "hypermodel = LSTMHyperModel(input_dim,feature_size,output_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tn9fLk2uwQsN",
        "outputId": "71abf9b5-76c8-41d4-c1b2-37e26dcb3af5"
      },
      "source": [
        "tuner_bo = BayesianOptimization(\n",
        "            hypermodel,\n",
        "            objective='val_mse',\n",
        "            max_trials=10,\n",
        "            seed=42,\n",
        "            executions_per_trial=2\n",
        "        )\n",
        "tuner_bo.search(X_train, Y_train, epochs=150, validation_data=(X_test, Y_test), verbose=4)\n",
        "best_model = tuner_bo.get_best_models(num_models=1)[0]\n",
        "best_model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 10 Complete [00h 04m 50s]\n",
            "val_mse: 1.3099586367607117\n",
            "\n",
            "Best val_mse So Far: 0.0015383216086775064\n",
            "Total elapsed time: 00h 44m 08s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "51/51 [==============================] - 2s 4ms/step - loss: 0.0015 - mse: 0.0015\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0015233262674883008, 0.0015233262674883008]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "628wjOsEwQsP",
        "outputId": "9e9cffcc-f319-46ef-cf33-ffcc7c927ac2"
      },
      "source": [
        "tuner_bo.results_summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results summary\n",
            "Results in ./untitled_project\n",
            "Showing 10 best trials\n",
            "Objective(name='val_mse', direction='min')\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units_directional: 448\n",
            "units_dense: 64\n",
            "dense_activation: tanh\n",
            "learning_rate: 0.001\n",
            "Score: 0.0015383216086775064\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units_directional: 448\n",
            "units_dense: 192\n",
            "dense_activation: sigmoid\n",
            "learning_rate: 0.001\n",
            "Score: 0.0015778450760990381\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units_directional: 480\n",
            "units_dense: 32\n",
            "dense_activation: sigmoid\n",
            "learning_rate: 0.002\n",
            "Score: 0.0016240469412878156\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units_directional: 352\n",
            "units_dense: 64\n",
            "dense_activation: tanh\n",
            "learning_rate: 0.002\n",
            "Score: 0.0022264543222263455\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units_directional: 512\n",
            "units_dense: 32\n",
            "dense_activation: relu\n",
            "learning_rate: 0.0003\n",
            "Score: 0.0092625527177006\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units_directional: 256\n",
            "units_dense: 32\n",
            "dense_activation: relu\n",
            "learning_rate: 0.01\n",
            "Score: 0.032957484014332294\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units_directional: 320\n",
            "units_dense: 32\n",
            "dense_activation: sigmoid\n",
            "learning_rate: 0.01\n",
            "Score: 0.043513487093150616\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units_directional: 512\n",
            "units_dense: 288\n",
            "dense_activation: relu\n",
            "learning_rate: 0.01\n",
            "Score: 0.3384568030014634\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units_directional: 512\n",
            "units_dense: 32\n",
            "dense_activation: relu\n",
            "learning_rate: 0.01\n",
            "Score: 1.3099586367607117\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units_directional: 64\n",
            "units_dense: 480\n",
            "dense_activation: sigmoid\n",
            "learning_rate: 0.05\n",
            "Score: 7.650115370750427\n"
          ],
          "name": "stdout"
        }
      ]
    }
<<<<<<< HEAD
<<<<<<< HEAD
   ],
   "source": [
    "tuner_bo.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
=======
  ]
>>>>>>> 02a2a658d495b21b2ea1262236116c19d5d23722
=======
  ]
>>>>>>> 02a2a658d495b21b2ea1262236116c19d5d23722
}
